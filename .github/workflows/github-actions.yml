name: Crawl PSJP everyday
on: push
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 2
      - run: git checkout HEAD^
      - run: pip install beautifulsoup4
      - run: sudo apt-get install -y jq
      - run: python crawl-psjp-data.py | jq -s . > data/data.json
      - name: git
        run: |
          git status
          git config --global user.name "${GITHUB_ACTOR}"
          git config --global user.email "${GITHUB_ACTOR}@users.noreply.github.com"
          git add data/data.json
          git commit -m "update data.json"
          git log
